{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "글씨체 분류기:\n",
    "머신러닝 학습을 통해 테스트 비율을 조정하며 정확도값과 평가지표들이 어떻게 되는지 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits #글씨체 데이터셋 가져오기\n",
    "\n",
    "digits=load_digits() #글씨체 데이터셋 변수에 저장해주기\n",
    "\n",
    "digits #글씨체 데이터셋에 무엇이 있는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_data = digits.data #디지털 데이터셋에 데이터들을 변수에 선언\n",
    "\n",
    "digits_label = digits.target #디지털 데이터셋에 타깃들을 변수에 선언\n",
    "\n",
    "digits_feature_name=digits.feature_names #디지털 데이터셋에 모양새들을 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       "0           0.0        0.0        5.0       13.0        9.0        1.0   \n",
       "1           0.0        0.0        0.0       12.0       13.0        5.0   \n",
       "2           0.0        0.0        0.0        4.0       15.0       12.0   \n",
       "3           0.0        0.0        7.0       15.0       13.0        1.0   \n",
       "4           0.0        0.0        0.0        1.0       11.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1792        0.0        0.0        4.0       10.0       13.0        6.0   \n",
       "1793        0.0        0.0        6.0       16.0       13.0       11.0   \n",
       "1794        0.0        0.0        1.0       11.0       15.0        1.0   \n",
       "1795        0.0        0.0        2.0       10.0        7.0        0.0   \n",
       "1796        0.0        0.0       10.0       14.0        8.0        1.0   \n",
       "\n",
       "      pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_7  pixel_7_0  \\\n",
       "0           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "2           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "3           0.0        0.0        0.0        8.0  ...        0.0        0.0   \n",
       "4           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "1792        0.0        0.0        0.0        1.0  ...        0.0        0.0   \n",
       "1793        1.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1794        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1795        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1796        0.0        0.0        0.0        2.0  ...        0.0        0.0   \n",
       "\n",
       "      pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  pixel_7_6  \\\n",
       "0           0.0        6.0       13.0       10.0        0.0        0.0   \n",
       "1           0.0        0.0       11.0       16.0       10.0        0.0   \n",
       "2           0.0        0.0        3.0       11.0       16.0        9.0   \n",
       "3           0.0        7.0       13.0       13.0        9.0        0.0   \n",
       "4           0.0        0.0        2.0       16.0        4.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1792        0.0        2.0       14.0       15.0        9.0        0.0   \n",
       "1793        0.0        6.0       16.0       14.0        6.0        0.0   \n",
       "1794        0.0        2.0        9.0       13.0        6.0        0.0   \n",
       "1795        0.0        5.0       12.0       16.0       12.0        0.0   \n",
       "1796        1.0        8.0       12.0       14.0       12.0        1.0   \n",
       "\n",
       "      pixel_7_7  label  \n",
       "0           0.0      0  \n",
       "1           0.0      1  \n",
       "2           0.0      2  \n",
       "3           0.0      3  \n",
       "4           0.0      4  \n",
       "...         ...    ...  \n",
       "1792        0.0      9  \n",
       "1793        0.0      0  \n",
       "1794        0.0      8  \n",
       "1795        0.0      9  \n",
       "1796        0.0      8  \n",
       "\n",
       "[1797 rows x 65 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd #pandas 를 pd로 선언할수 있게끔 설정\n",
    "\n",
    "digits_df = pd.DataFrame(data = digits_data,\n",
    "                        columns = digits_feature_name)#데이터들을 보다 보기 더 쉽게 표로 정리\n",
    "\n",
    "digits_df[\"label\"] = digits_label #만든표에 타깃도 넣어주기\n",
    "\n",
    "digits_df #표 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.81      0.81      0.81        42\n",
      "           2       0.79      0.82      0.80        40\n",
      "           3       0.79      0.91      0.85        34\n",
      "           4       0.83      0.95      0.89        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       0.84      0.93      0.88        28\n",
      "           7       0.96      0.82      0.89        33\n",
      "           8       0.88      0.65      0.75        43\n",
      "           9       0.78      0.78      0.78        32\n",
      "\n",
      "    accuracy                           0.86       360\n",
      "   macro avg       0.86      0.86      0.86       360\n",
      "weighted avg       0.86      0.86      0.85       360\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        45\n",
      "           1       0.77      0.86      0.81        43\n",
      "           2       0.86      0.82      0.84        44\n",
      "           3       0.86      0.91      0.89        34\n",
      "           4       0.80      0.95      0.87        38\n",
      "           5       0.93      0.97      0.95        29\n",
      "           6       0.90      0.93      0.92        30\n",
      "           7       0.90      0.80      0.85        35\n",
      "           8       0.85      0.65      0.74        43\n",
      "           9       0.82      0.84      0.83        37\n",
      "\n",
      "    accuracy                           0.87       378\n",
      "   macro avg       0.87      0.87      0.87       378\n",
      "weighted avg       0.87      0.87      0.86       378\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        48\n",
      "           1       0.80      0.78      0.79        45\n",
      "           2       0.79      0.84      0.81        44\n",
      "           3       0.84      0.91      0.88        35\n",
      "           4       0.88      0.90      0.89        39\n",
      "           5       0.91      0.97      0.94        31\n",
      "           6       0.91      0.94      0.92        32\n",
      "           7       0.94      0.82      0.87        38\n",
      "           8       0.86      0.67      0.75        45\n",
      "           9       0.73      0.85      0.79        39\n",
      "\n",
      "    accuracy                           0.86       396\n",
      "   macro avg       0.86      0.86      0.86       396\n",
      "weighted avg       0.86      0.86      0.86       396\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        48\n",
      "           1       0.85      0.83      0.84        48\n",
      "           2       0.83      0.86      0.84        44\n",
      "           3       0.80      0.92      0.86        39\n",
      "           4       0.84      0.84      0.84        43\n",
      "           5       0.91      0.97      0.94        31\n",
      "           6       0.94      0.94      0.94        34\n",
      "           7       0.84      0.82      0.83        38\n",
      "           8       0.91      0.65      0.76        48\n",
      "           9       0.74      0.83      0.78        41\n",
      "\n",
      "    accuracy                           0.86       414\n",
      "   macro avg       0.86      0.86      0.86       414\n",
      "weighted avg       0.86      0.86      0.86       414\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        49\n",
      "           1       0.80      0.81      0.80        48\n",
      "           2       0.82      0.87      0.84        46\n",
      "           3       0.70      0.93      0.80        42\n",
      "           4       0.90      0.81      0.85        43\n",
      "           5       0.83      0.97      0.89        35\n",
      "           6       0.97      0.95      0.96        37\n",
      "           7       0.89      0.78      0.83        40\n",
      "           8       0.86      0.62      0.72        50\n",
      "           9       0.76      0.76      0.76        42\n",
      "\n",
      "    accuracy                           0.84       432\n",
      "   macro avg       0.85      0.85      0.84       432\n",
      "weighted avg       0.85      0.84      0.84       432\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        52\n",
      "           1       0.87      0.81      0.84        48\n",
      "           2       0.77      0.85      0.81        48\n",
      "           3       0.82      0.93      0.87        43\n",
      "           4       0.83      0.83      0.83        47\n",
      "           5       0.90      0.97      0.94        38\n",
      "           6       0.97      0.95      0.96        38\n",
      "           7       0.71      0.83      0.76        41\n",
      "           8       0.89      0.68      0.77        50\n",
      "           9       0.81      0.76      0.78        45\n",
      "\n",
      "    accuracy                           0.85       450\n",
      "   macro avg       0.86      0.86      0.85       450\n",
      "weighted avg       0.86      0.85      0.85       450\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        55\n",
      "           1       0.81      0.81      0.81        48\n",
      "           2       0.81      0.86      0.83        49\n",
      "           3       0.76      0.93      0.84        45\n",
      "           4       0.89      0.82      0.85        50\n",
      "           5       0.91      0.97      0.94        40\n",
      "           6       0.93      0.95      0.94        42\n",
      "           7       0.69      0.83      0.76        41\n",
      "           8       0.92      0.63      0.75        52\n",
      "           9       0.81      0.76      0.79        46\n",
      "\n",
      "    accuracy                           0.85       468\n",
      "   macro avg       0.85      0.85      0.85       468\n",
      "weighted avg       0.86      0.85      0.85       468\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        55\n",
      "           1       0.81      0.84      0.82        50\n",
      "           2       0.78      0.80      0.79        49\n",
      "           3       0.76      0.89      0.82        47\n",
      "           4       0.90      0.87      0.88        52\n",
      "           5       0.93      0.98      0.95        41\n",
      "           6       1.00      0.95      0.98        42\n",
      "           7       0.76      0.87      0.81        45\n",
      "           8       0.88      0.69      0.78        55\n",
      "           9       0.81      0.76      0.78        50\n",
      "\n",
      "    accuracy                           0.86       486\n",
      "   macro avg       0.86      0.86      0.86       486\n",
      "weighted avg       0.86      0.86      0.86       486\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97        56\n",
      "           1       0.82      0.87      0.84        52\n",
      "           2       0.83      0.83      0.83        52\n",
      "           3       0.78      0.90      0.83        48\n",
      "           4       0.88      0.87      0.88        53\n",
      "           5       0.91      0.98      0.94        42\n",
      "           6       0.94      0.96      0.95        46\n",
      "           7       0.76      0.83      0.79        46\n",
      "           8       0.89      0.68      0.77        57\n",
      "           9       0.80      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.86       504\n",
      "   macro avg       0.86      0.86      0.86       504\n",
      "weighted avg       0.86      0.86      0.86       504\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        58\n",
      "           1       0.73      0.83      0.77        52\n",
      "           2       0.84      0.90      0.87        52\n",
      "           3       0.72      0.80      0.76        49\n",
      "           4       0.89      0.88      0.88        57\n",
      "           5       0.91      0.93      0.92        46\n",
      "           6       1.00      0.96      0.98        48\n",
      "           7       0.81      0.79      0.80        48\n",
      "           8       0.96      0.75      0.84        59\n",
      "           9       0.75      0.77      0.76        53\n",
      "\n",
      "    accuracy                           0.86       522\n",
      "   macro avg       0.86      0.86      0.86       522\n",
      "weighted avg       0.86      0.86      0.86       522\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        61\n",
      "           1       0.73      0.84      0.78        55\n",
      "           2       0.84      0.92      0.88        53\n",
      "           3       0.70      0.77      0.73        52\n",
      "           4       0.91      0.86      0.88        58\n",
      "           5       0.88      0.94      0.91        48\n",
      "           6       1.00      0.96      0.98        48\n",
      "           7       0.78      0.78      0.78        49\n",
      "           8       0.93      0.69      0.80        62\n",
      "           9       0.81      0.80      0.80        54\n",
      "\n",
      "    accuracy                           0.85       540\n",
      "   macro avg       0.85      0.85      0.85       540\n",
      "weighted avg       0.86      0.85      0.85       540\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        63\n",
      "           1       0.75      0.71      0.73        56\n",
      "           2       0.82      0.91      0.86        54\n",
      "           3       0.79      0.83      0.81        53\n",
      "           4       0.87      0.90      0.89        60\n",
      "           5       0.80      0.96      0.87        49\n",
      "           6       0.96      0.96      0.96        50\n",
      "           7       0.82      0.82      0.82        50\n",
      "           8       0.93      0.66      0.77        65\n",
      "           9       0.80      0.81      0.80        58\n",
      "\n",
      "    accuracy                           0.85       558\n",
      "   macro avg       0.85      0.85      0.85       558\n",
      "weighted avg       0.85      0.85      0.85       558\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93        63\n",
      "           1       0.75      0.79      0.77        57\n",
      "           2       0.85      0.91      0.88        56\n",
      "           3       0.78      0.78      0.78        54\n",
      "           4       0.88      0.87      0.87        60\n",
      "           5       0.81      0.92      0.86        50\n",
      "           6       0.94      0.94      0.94        52\n",
      "           7       0.71      0.75      0.73        56\n",
      "           8       0.88      0.69      0.77        67\n",
      "           9       0.89      0.80      0.84        61\n",
      "\n",
      "    accuracy                           0.84       576\n",
      "   macro avg       0.84      0.84      0.84       576\n",
      "weighted avg       0.84      0.84      0.84       576\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94        63\n",
      "           1       0.83      0.84      0.83        57\n",
      "           2       0.85      0.91      0.88        57\n",
      "           3       0.76      0.77      0.77        57\n",
      "           4       0.78      0.89      0.83        64\n",
      "           5       0.82      0.96      0.88        51\n",
      "           6       1.00      0.95      0.97        56\n",
      "           7       0.85      0.79      0.82        58\n",
      "           8       0.88      0.71      0.78        69\n",
      "           9       0.84      0.77      0.81        62\n",
      "\n",
      "    accuracy                           0.85       594\n",
      "   macro avg       0.85      0.86      0.85       594\n",
      "weighted avg       0.85      0.85      0.85       594\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        63\n",
      "           1       0.80      0.84      0.82        58\n",
      "           2       0.83      0.90      0.86        59\n",
      "           3       0.81      0.78      0.80        60\n",
      "           4       0.84      0.86      0.85        65\n",
      "           5       0.77      0.94      0.84        52\n",
      "           6       0.95      0.93      0.94        59\n",
      "           7       0.86      0.79      0.82        61\n",
      "           8       0.83      0.71      0.77        69\n",
      "           9       0.82      0.77      0.79        65\n",
      "\n",
      "    accuracy                           0.84       611\n",
      "   macro avg       0.85      0.85      0.84       611\n",
      "weighted avg       0.85      0.84      0.84       611\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        64\n",
      "           1       0.77      0.88      0.82        60\n",
      "           2       0.83      0.92      0.87        59\n",
      "           3       0.83      0.79      0.81        62\n",
      "           4       0.83      0.85      0.84        67\n",
      "           5       0.82      0.94      0.88        54\n",
      "           6       0.97      0.93      0.95        61\n",
      "           7       0.86      0.80      0.83        64\n",
      "           8       0.84      0.71      0.77        72\n",
      "           9       0.82      0.77      0.80        66\n",
      "\n",
      "    accuracy                           0.85       629\n",
      "   macro avg       0.85      0.85      0.85       629\n",
      "weighted avg       0.85      0.85      0.85       629\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        65\n",
      "           1       0.69      0.81      0.75        62\n",
      "           2       0.84      0.92      0.88        59\n",
      "           3       0.85      0.75      0.80        63\n",
      "           4       0.78      0.86      0.81        69\n",
      "           5       0.85      0.95      0.90        55\n",
      "           6       0.95      0.94      0.94        62\n",
      "           7       0.86      0.82      0.84        67\n",
      "           8       0.86      0.68      0.76        79\n",
      "           9       0.82      0.82      0.82        66\n",
      "\n",
      "    accuracy                           0.84       647\n",
      "   macro avg       0.85      0.85      0.84       647\n",
      "weighted avg       0.85      0.84      0.84       647\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        66\n",
      "           1       0.72      0.85      0.78        65\n",
      "           2       0.84      0.92      0.88        62\n",
      "           3       0.85      0.80      0.83        66\n",
      "           4       0.81      0.86      0.83        70\n",
      "           5       0.75      0.90      0.82        58\n",
      "           6       0.95      0.94      0.94        63\n",
      "           7       0.88      0.78      0.83        68\n",
      "           8       0.86      0.69      0.76        80\n",
      "           9       0.83      0.79      0.81        67\n",
      "\n",
      "    accuracy                           0.84       665\n",
      "   macro avg       0.85      0.85      0.84       665\n",
      "weighted avg       0.85      0.84      0.84       665\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95        67\n",
      "           1       0.75      0.84      0.79        67\n",
      "           2       0.88      0.93      0.90        68\n",
      "           3       0.83      0.78      0.80        67\n",
      "           4       0.85      0.86      0.85        71\n",
      "           5       0.86      0.92      0.89        59\n",
      "           6       0.95      0.94      0.95        65\n",
      "           7       0.84      0.81      0.82        69\n",
      "           8       0.87      0.72      0.78        81\n",
      "           9       0.79      0.83      0.81        69\n",
      "\n",
      "    accuracy                           0.85       683\n",
      "   macro avg       0.85      0.86      0.85       683\n",
      "weighted avg       0.85      0.85      0.85       683\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        68\n",
      "           1       0.75      0.86      0.80        70\n",
      "           2       0.85      0.88      0.86        73\n",
      "           3       0.79      0.84      0.81        68\n",
      "           4       0.87      0.90      0.89        73\n",
      "           5       0.86      0.92      0.89        60\n",
      "           6       0.97      0.94      0.95        67\n",
      "           7       0.87      0.78      0.82        69\n",
      "           8       0.88      0.72      0.79        83\n",
      "           9       0.82      0.83      0.82        70\n",
      "\n",
      "    accuracy                           0.86       701\n",
      "   macro avg       0.86      0.86      0.86       701\n",
      "weighted avg       0.86      0.86      0.86       701\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "test_size_list=list(range(20,40))\n",
    "a= [i/100 for i in  test_size_list] #0.2~0.4까지 변수에 저장\n",
    "for i in a:\n",
    "#트레인과 테스트 데이터셋 분리\n",
    "    X_train, X_test, y_train, y_test = train_test_split(digits_data, \n",
    "                                                        digits_label, \n",
    "                                                        test_size=i, #0.2~0.4까지 20개를 본다\n",
    "                                                        random_state=7)\n",
    "    decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "    decision_tree.fit(X_train, y_train) #모델학습\n",
    "    y_pred = decision_tree.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보시면 아시겠지만 test size=0.21일때 가장 정확도가 크게나왔으며, 데이터량이 그렇게 방대하지않아 테스트사이즈를 더 줄이면 테스트 비용이 작아져 0.2~0.4로 설정을 하였고 precision, recall, f1값 세개의 지표가 잘 나왔다.\n",
    "내가 생각할때는 이 글씨체 분류기는 재현율이 중요하다고 생각한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
